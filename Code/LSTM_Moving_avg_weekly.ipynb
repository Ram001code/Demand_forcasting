{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a120720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d8c816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Mv_Qty</th>\n",
       "      <th>Mv_Amt</th>\n",
       "      <th>Location</th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>86.101210</td>\n",
       "      <td>429.645000</td>\n",
       "      <td>55.004790</td>\n",
       "      <td>274.473889</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>63.834068</td>\n",
       "      <td>318.532000</td>\n",
       "      <td>63.941686</td>\n",
       "      <td>319.069000</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>45.320977</td>\n",
       "      <td>226.151667</td>\n",
       "      <td>65.085418</td>\n",
       "      <td>324.776222</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>44.333068</td>\n",
       "      <td>221.222000</td>\n",
       "      <td>51.162704</td>\n",
       "      <td>255.301889</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>48.167670</td>\n",
       "      <td>240.356667</td>\n",
       "      <td>45.940572</td>\n",
       "      <td>229.243444</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Quantity      Amount     Mv_Qty      Mv_Amt Location  \\\n",
       "0 2020-01-19  86.101210  429.645000  55.004790  274.473889  FREMONT   \n",
       "1 2020-01-26  63.834068  318.532000  63.941686  319.069000  FREMONT   \n",
       "2 2020-02-02  45.320977  226.151667  65.085418  324.776222  FREMONT   \n",
       "3 2020-02-09  44.333068  221.222000  51.162704  255.301889  FREMONT   \n",
       "4 2020-02-16  48.167670  240.356667  45.940572  229.243444  FREMONT   \n",
       "\n",
       "                Item  \n",
       "0  CHICKEN XXXXX - O  \n",
       "1  CHICKEN XXXXX - O  \n",
       "2  CHICKEN XXXXX - O  \n",
       "3  CHICKEN XXXXX - O  \n",
       "4  CHICKEN XXXXX - O  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc= 'C:\\\\Users\\\\Ramshankar\\\\OneDrive - iLink Systems Inc\\\\Documents\\\\Costco\\\\Dataset\\\\Final Output\\\\Weekly\\\\'\n",
    "\n",
    "\n",
    "data= pd.read_excel(loc + 'Data_Moving_avg.xlsx', index_col=False)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaccad28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2099, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5871b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "data_df= copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cebbb211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = data_df.loc[data_df['Date'] <= '2022-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c36a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new= data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "deb8163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df2 = df_new[(df_new['Location']=='FREMONT') & (df_new['Item']== 'FILLET QQQQ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5133e861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 7)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b2ea991",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df2 = data_df2.drop(['Location', 'Item', 'Amount', 'Mv_Amt','Quantity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e5546b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df2= data_df2.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4a85d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_df2[data_df2['Date']<= '2022-05-01']\n",
    "test = data_df2[data_df2['Date']>= '2022-05-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "099c3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= train.set_index('Date')\n",
    "test= test.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8b8d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a= int(len(data_df2)*0.80)\n",
    "\n",
    "# train,test = data_df2[:a], data_df2[a:]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train) \n",
    "\n",
    "train_scaled = scaler.transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ed19027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 1), (31, 1))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "819ecccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mv_Qty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>42.715309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08</th>\n",
       "      <td>39.546157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-15</th>\n",
       "      <td>40.695451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-22</th>\n",
       "      <td>40.292686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-29</th>\n",
       "      <td>40.629181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-05</th>\n",
       "      <td>42.348401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-12</th>\n",
       "      <td>47.911189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19</th>\n",
       "      <td>48.941414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>45.564168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-03</th>\n",
       "      <td>43.082983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-10</th>\n",
       "      <td>44.916350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-17</th>\n",
       "      <td>47.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-24</th>\n",
       "      <td>46.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-31</th>\n",
       "      <td>42.540935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-07</th>\n",
       "      <td>43.428523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-14</th>\n",
       "      <td>45.091922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-21</th>\n",
       "      <td>49.046869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>47.504547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-04</th>\n",
       "      <td>43.894155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-11</th>\n",
       "      <td>41.137624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-18</th>\n",
       "      <td>43.243192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-25</th>\n",
       "      <td>43.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02</th>\n",
       "      <td>41.271312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-09</th>\n",
       "      <td>43.341916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-16</th>\n",
       "      <td>44.250171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-23</th>\n",
       "      <td>45.469936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30</th>\n",
       "      <td>40.638218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-06</th>\n",
       "      <td>40.872342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-13</th>\n",
       "      <td>42.864240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-20</th>\n",
       "      <td>40.785055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>41.208001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mv_Qty\n",
       "Date                 \n",
       "2022-05-01  42.715309\n",
       "2022-05-08  39.546157\n",
       "2022-05-15  40.695451\n",
       "2022-05-22  40.292686\n",
       "2022-05-29  40.629181\n",
       "2022-06-05  42.348401\n",
       "2022-06-12  47.911189\n",
       "2022-06-19  48.941414\n",
       "2022-06-26  45.564168\n",
       "2022-07-03  43.082983\n",
       "2022-07-10  44.916350\n",
       "2022-07-17  47.000264\n",
       "2022-07-24  46.000225\n",
       "2022-07-31  42.540935\n",
       "2022-08-07  43.428523\n",
       "2022-08-14  45.091922\n",
       "2022-08-21  49.046869\n",
       "2022-08-28  47.504547\n",
       "2022-09-04  43.894155\n",
       "2022-09-11  41.137624\n",
       "2022-09-18  43.243192\n",
       "2022-09-25  43.591516\n",
       "2022-10-02  41.271312\n",
       "2022-10-09  43.341916\n",
       "2022-10-16  44.250171\n",
       "2022-10-23  45.469936\n",
       "2022-10-30  40.638218\n",
       "2022-11-06  40.872342\n",
       "2022-11-13  42.864240\n",
       "2022-11-20  40.785055\n",
       "2022-11-27  41.208001"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c31c1bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty lists to be populated using formatted training data\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past=seq_size = 5  # Number of past days we want to use to predict the future.\n",
    "n_features = 1 ## number of features. This dataset is univariate so it is 1\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "\n",
    "for i in range(n_past, len(train_scaled) - n_future +1):\n",
    "    trainX.append(train_scaled[i - n_past:i, 0:train.shape[1]])\n",
    "    trainY.append(train_scaled[i + n_future - 1:i + n_future, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a74aace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape == (115, 5, 1).\n",
      "trainY shape == (115, 1).\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "print('trainX shape == {}.'.format(trainX.shape))\n",
    "print('trainY shape == {}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4b770968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_36 (LSTM)              (None, 5, 128)            66560     \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 5, 64)             49408     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 5, 64)             0         \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 5, 32)             12416     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 5, 32)             0         \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 5, 16)             3136      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 5, 16)             0         \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, 8)                 800       \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,371\n",
      "Trainable params: 132,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "# model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(LSTM(16, activation='relu', return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(8, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "840c5900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 18s 454ms/step - loss: 0.3943 - val_loss: 0.2403\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3622 - val_loss: 0.2103\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3270 - val_loss: 0.1791\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2853 - val_loss: 0.1438\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2626 - val_loss: 0.1070\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2133 - val_loss: 0.1253\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2417 - val_loss: 0.1078\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2249 - val_loss: 0.1058\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1939 - val_loss: 0.1068\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1829 - val_loss: 0.1098\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1952 - val_loss: 0.1116\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1948 - val_loss: 0.1041\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1813 - val_loss: 0.1033\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2158 - val_loss: 0.1034\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1879 - val_loss: 0.1028\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2071 - val_loss: 0.1019\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1847 - val_loss: 0.0995\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1855 - val_loss: 0.1012\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1708 - val_loss: 0.0986\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1863 - val_loss: 0.1001\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1638 - val_loss: 0.0972\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1607 - val_loss: 0.0968\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1684 - val_loss: 0.0958\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1656 - val_loss: 0.0967\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1739 - val_loss: 0.0949\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1519 - val_loss: 0.0958\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1494 - val_loss: 0.1014\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1589 - val_loss: 0.0986\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1481 - val_loss: 0.0965\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1506 - val_loss: 0.0956\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, epochs=30, batch_size=16, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d696ae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24f68804b50>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "36219910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "train_inverse = scaler.inverse_transform(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "555e4585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainPredict.shape,train_inverse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1d137dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_past=5\n",
    "# train_inverse[n_past:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5433a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 2593.28 MSE\n",
      "Train Score: 50.92 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "n_past=5\n",
    "\n",
    "MSE_Score = mean_squared_error(train_inverse[n_past:], trainPredict[:,0])\n",
    "print('Train Score: %.2f MSE' % (MSE_Score))\n",
    "\n",
    "RMSE_Score = math.sqrt(mean_squared_error(train_inverse[n_past:], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (RMSE_Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7bd4b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 5, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 5, 1), dtype=tf.float32, name='lstm_36_input'), name='lstm_36_input', description=\"created by layer 'lstm_36_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "testPredict = model.predict(test)\n",
    "test_inverse = scaler.inverse_transform(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "05a7a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 1735.83 MSE\n",
      "Test Score: 41.66 RMSE\n"
     ]
    }
   ],
   "source": [
    "MSE_Score = mean_squared_error(test_inverse[:], testPredict[:,0])\n",
    "print('Test Score: %.2f MSE' % (MSE_Score))\n",
    "\n",
    "RMSE_Score = math.sqrt(mean_squared_error(test_inverse[:], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (RMSE_Score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "253784d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_past= seq_size= 1          # 1 means-1 week back\n",
    "# n_days_for_prediction = 36  #let us predict past 12 days\n",
    "\n",
    "\n",
    "# from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "# from pandas.tseries.offsets import CustomBusinessDay\n",
    "# us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "\n",
    "\n",
    "# train_dates = pd.to_datetime(data_df2['Date'])\n",
    "time_series = test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "efda0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_period_dates = pd.date_range(list(time_series)[-1], periods=n_days_for_prediction, freq='W').tolist()\n",
    "# print(predict_period_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0b52bbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a74c7895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4f93f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inverse transform to before scaling so we get actual numbers\n",
    "rescaled_prediction = scaler.inverse_transform(prediction)[:,0]\n",
    "\n",
    "# Convert timestamp to date\n",
    "forecast_dates = []\n",
    "for time_i in time_series:\n",
    "    forecast_dates.append(time_i.date())\n",
    "    \n",
    "df_forecast= pd.DataFrame({'Date':np.array(forecast_dates), 'Quantity':rescaled_prediction})\n",
    "df_forecast['Date']=pd.to_datetime(df_forecast['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc0313f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\AppData\\Local\\Temp\\ipykernel_2956\\2158661631.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  original['Date']=pd.to_datetime(original['Date'])\n"
     ]
    }
   ],
   "source": [
    "#reset index\n",
    "data_df3= data_df2.reset_index()\n",
    "\n",
    "original = data_df3[['Date', 'Mv_Qty']]\n",
    "original['Date']=pd.to_datetime(original['Date'])\n",
    "original = original.loc[original['Date'] >= '2020-01-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6f26cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramshankar\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,8)) \n",
    "lineplt= sns.lineplot(original['Date'], original['Mv_Qty'])\n",
    "sns.lineplot(df_forecast['Date'], df_forecast['Quantity'])\n",
    "# lineplt.set(title = 'SAN FRANCISCO--> BEEF OOOO - GT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c90bc",
   "metadata": {},
   "source": [
    "### All in one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47a8e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.loc[df_new['Date'] <= '2022-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9ffb83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Mv_Qty</th>\n",
       "      <th>Mv_Amt</th>\n",
       "      <th>Location</th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>107.244448</td>\n",
       "      <td>106.172000</td>\n",
       "      <td>110.342874</td>\n",
       "      <td>109.239444</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>2022-03-06</td>\n",
       "      <td>93.272733</td>\n",
       "      <td>92.340000</td>\n",
       "      <td>94.878907</td>\n",
       "      <td>93.930111</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>2022-03-13</td>\n",
       "      <td>112.682822</td>\n",
       "      <td>111.556000</td>\n",
       "      <td>104.400001</td>\n",
       "      <td>103.356000</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>122.062285</td>\n",
       "      <td>120.841667</td>\n",
       "      <td>109.339280</td>\n",
       "      <td>108.245889</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>102.385522</td>\n",
       "      <td>101.361667</td>\n",
       "      <td>112.376876</td>\n",
       "      <td>111.253111</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Quantity      Amount      Mv_Qty      Mv_Amt  \\\n",
       "2059 2022-02-27  107.244448  106.172000  110.342874  109.239444   \n",
       "2060 2022-03-06   93.272733   92.340000   94.878907   93.930111   \n",
       "2061 2022-03-13  112.682822  111.556000  104.400001  103.356000   \n",
       "2062 2022-03-20  122.062285  120.841667  109.339280  108.245889   \n",
       "2063 2022-03-27  102.385522  101.361667  112.376876  111.253111   \n",
       "\n",
       "                     Location             Item  \n",
       "2059  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN  \n",
       "2060  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN  \n",
       "2061  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN  \n",
       "2062  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN  \n",
       "2063  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "941a59e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Archtitecture FREMONT--> CHICKEN XXXXX - O\n",
      "Model Training: FREMONT--> CHICKEN XXXXX - O\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 423ms/step - loss: 0.2839 - val_loss: 0.0309\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2721 - val_loss: 0.0270\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2561 - val_loss: 0.0226\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2379 - val_loss: 0.0179\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2202 - val_loss: 0.0129\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1944 - val_loss: 0.0081\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1599 - val_loss: 0.0051\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1140 - val_loss: 0.0087\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0762 - val_loss: 0.0323\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0624 - val_loss: 0.0653\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0719 - val_loss: 0.0539\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0602 - val_loss: 0.0311\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0642 - val_loss: 0.0235\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0634 - val_loss: 0.0262\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0575 - val_loss: 0.0352\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0570 - val_loss: 0.0478\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0593 - val_loss: 0.0559\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0502 - val_loss: 0.0534\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0550 - val_loss: 0.0441\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0582 - val_loss: 0.0393\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0509 - val_loss: 0.0398\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0644 - val_loss: 0.0433\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0634 - val_loss: 0.0470\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0572 - val_loss: 0.0525\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0566 - val_loss: 0.0512\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0504 - val_loss: 0.0467\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0542 - val_loss: 0.0444\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0598 - val_loss: 0.0449\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0508 - val_loss: 0.0490\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0571 - val_loss: 0.0528\n",
      "\n",
      "\n",
      "Plot for: FREMONT--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Model Forecasting initated: FREMONT--> CHICKEN XXXXX - O\n",
      "Model prediction initiated : FREMONT--> CHICKEN XXXXX - O\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "Model prediction completed : FREMONT--> CHICKEN XXXXX - O\n",
      "Storing prediction into DataFrame : FREMONT--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Plotting prediction with original data : FREMONT--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : FREMONT--> CHICKEN XXXXX - O\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "Train Score FREMONT-CHICKEN XXXXX - O: 7693.16 MSE\n",
      "Train Score FREMONT-CHICKEN XXXXX - O: 87.71 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of FREMONT and CHICKEN XXXXX - O\n",
      "Writing error matrices of FREMONT and CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "LSTM Archtitecture FREMONT--> DRUMSTICKS NNNN\n",
      "Model Training: FREMONT--> DRUMSTICKS NNNN\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 9s 401ms/step - loss: 0.3018 - val_loss: 0.2282\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2756 - val_loss: 0.2048\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2496 - val_loss: 0.1772\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2179 - val_loss: 0.1442\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1808 - val_loss: 0.1045\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1348 - val_loss: 0.0589\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0810 - val_loss: 0.0163\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0436 - val_loss: 0.0116\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0489 - val_loss: 0.0179\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0434 - val_loss: 0.0066\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0330 - val_loss: 0.0073\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0386 - val_loss: 0.0100\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0387 - val_loss: 0.0080\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0396 - val_loss: 0.0054\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0392 - val_loss: 0.0059\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0438 - val_loss: 0.0054\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0407 - val_loss: 0.0053\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0431 - val_loss: 0.0052\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0329 - val_loss: 0.0052\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0409 - val_loss: 0.0052\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0413 - val_loss: 0.0054\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0291 - val_loss: 0.0052\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0292 - val_loss: 0.0052\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0333 - val_loss: 0.0051\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0293 - val_loss: 0.0051\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0299 - val_loss: 0.0051\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0274 - val_loss: 0.0051\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0332 - val_loss: 0.0050\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0389 - val_loss: 0.0049\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0339 - val_loss: 0.0050\n",
      "\n",
      "\n",
      "Plot for: FREMONT--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Model Forecasting initated: FREMONT--> DRUMSTICKS NNNN\n",
      "Model prediction initiated : FREMONT--> DRUMSTICKS NNNN\n",
      "2/2 [==============================] - 1s 10ms/step\n",
      "Model prediction completed : FREMONT--> DRUMSTICKS NNNN\n",
      "Storing prediction into DataFrame : FREMONT--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Plotting prediction with original data : FREMONT--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : FREMONT--> DRUMSTICKS NNNN\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "Train Score FREMONT-DRUMSTICKS NNNN: 321932.69 MSE\n",
      "Train Score FREMONT-DRUMSTICKS NNNN: 567.39 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of FREMONT and DRUMSTICKS NNNN\n",
      "Writing error matrices of FREMONT and DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "LSTM Archtitecture FREMONT--> FILLET QQQQ\n",
      "Model Training: FREMONT--> FILLET QQQQ\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 367ms/step - loss: 0.3129 - val_loss: 0.0171\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2880 - val_loss: 0.0128\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2605 - val_loss: 0.0087\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2272 - val_loss: 0.0056\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1796 - val_loss: 0.0056\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1334 - val_loss: 0.0126\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0766 - val_loss: 0.0361\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0419 - val_loss: 0.0864\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0517 - val_loss: 0.1105\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0464 - val_loss: 0.0811\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0376 - val_loss: 0.0576\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0391 - val_loss: 0.0510\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0372 - val_loss: 0.0536\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0307 - val_loss: 0.0584\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0340 - val_loss: 0.0691\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0340 - val_loss: 0.0761\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0369 - val_loss: 0.0712\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0326 - val_loss: 0.0632\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0369 - val_loss: 0.0575\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0346 - val_loss: 0.0541\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0342 - val_loss: 0.0559\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0315 - val_loss: 0.0599\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0350 - val_loss: 0.0596\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0300 - val_loss: 0.0573\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0375 - val_loss: 0.0541\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0294 - val_loss: 0.0566\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0283 - val_loss: 0.0570\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0392 - val_loss: 0.0487\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0299 - val_loss: 0.0466\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0310 - val_loss: 0.0470\n",
      "\n",
      "\n",
      "Plot for: FREMONT--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Model Forecasting initated: FREMONT--> FILLET QQQQ\n",
      "Model prediction initiated : FREMONT--> FILLET QQQQ\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "Model prediction completed : FREMONT--> FILLET QQQQ\n",
      "Storing prediction into DataFrame : FREMONT--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Plotting prediction with original data : FREMONT--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : FREMONT--> FILLET QQQQ\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Train Score FREMONT-FILLET QQQQ: 2873.28 MSE\n",
      "Train Score FREMONT-FILLET QQQQ: 53.60 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of FREMONT and FILLET QQQQ\n",
      "Writing error matrices of FREMONT and FILLET QQQQ\n",
      "\n",
      "\n",
      "LSTM Archtitecture HAYWARD--> CHICKEN XXXXX - O\n",
      "Model Training: HAYWARD--> CHICKEN XXXXX - O\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 9s 390ms/step - loss: 0.1942 - val_loss: 0.1928\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1789 - val_loss: 0.1751\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1591 - val_loss: 0.1550\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1375 - val_loss: 0.1316\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1106 - val_loss: 0.1049\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0857 - val_loss: 0.0778\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0613 - val_loss: 0.0616\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0578 - val_loss: 0.0720\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0505 - val_loss: 0.0695\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0496 - val_loss: 0.0611\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0510 - val_loss: 0.0599\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0487 - val_loss: 0.0604\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0485 - val_loss: 0.0596\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0464 - val_loss: 0.0591\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0435 - val_loss: 0.0594\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0402 - val_loss: 0.0594\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0453 - val_loss: 0.0593\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0444 - val_loss: 0.0583\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0456 - val_loss: 0.0579\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0429 - val_loss: 0.0576\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0440 - val_loss: 0.0575\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0443 - val_loss: 0.0576\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0376 - val_loss: 0.0586\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0421 - val_loss: 0.0586\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0375 - val_loss: 0.0568\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0437 - val_loss: 0.0564\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0413 - val_loss: 0.0556\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0500 - val_loss: 0.0553\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0391 - val_loss: 0.0550\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0350 - val_loss: 0.0558\n",
      "\n",
      "\n",
      "Plot for: HAYWARD--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Model Forecasting initated: HAYWARD--> CHICKEN XXXXX - O\n",
      "Model prediction initiated : HAYWARD--> CHICKEN XXXXX - O\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "Model prediction completed : HAYWARD--> CHICKEN XXXXX - O\n",
      "Storing prediction into DataFrame : HAYWARD--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Plotting prediction with original data : HAYWARD--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : HAYWARD--> CHICKEN XXXXX - O\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Train Score HAYWARD-CHICKEN XXXXX - O: 4694.71 MSE\n",
      "Train Score HAYWARD-CHICKEN XXXXX - O: 68.52 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of HAYWARD and CHICKEN XXXXX - O\n",
      "Writing error matrices of HAYWARD and CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "LSTM Archtitecture HAYWARD--> DRUMSTICKS NNNN\n",
      "Model Training: HAYWARD--> DRUMSTICKS NNNN\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 384ms/step - loss: 0.5157 - val_loss: 0.1960\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4971 - val_loss: 0.1885\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4796 - val_loss: 0.1800\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4570 - val_loss: 0.1701\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4355 - val_loss: 0.1580\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4038 - val_loss: 0.1435\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3598 - val_loss: 0.1263\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3043 - val_loss: 0.1061\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2382 - val_loss: 0.0849\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1503 - val_loss: 0.0722\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0635 - val_loss: 0.1035\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0954 - val_loss: 0.1201\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0833 - val_loss: 0.0857\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0468 - val_loss: 0.0751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0711 - val_loss: 0.0735\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0700 - val_loss: 0.0756\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0512 - val_loss: 0.0813\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0567 - val_loss: 0.0916\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0509 - val_loss: 0.0983\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0417 - val_loss: 0.0977\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0439 - val_loss: 0.0927\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0442 - val_loss: 0.0890\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0436 - val_loss: 0.0881\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0472 - val_loss: 0.0892\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0478 - val_loss: 0.0907\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0450 - val_loss: 0.0934\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0539 - val_loss: 0.0956\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0479 - val_loss: 0.0959\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0389 - val_loss: 0.0962\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0513 - val_loss: 0.0914\n",
      "\n",
      "\n",
      "Plot for: HAYWARD--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Model Forecasting initated: HAYWARD--> DRUMSTICKS NNNN\n",
      "Model prediction initiated : HAYWARD--> DRUMSTICKS NNNN\n",
      "2/2 [==============================] - 1s 9ms/step\n",
      "Model prediction completed : HAYWARD--> DRUMSTICKS NNNN\n",
      "Storing prediction into DataFrame : HAYWARD--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Plotting prediction with original data : HAYWARD--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : HAYWARD--> DRUMSTICKS NNNN\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Train Score HAYWARD-DRUMSTICKS NNNN: 291303.87 MSE\n",
      "Train Score HAYWARD-DRUMSTICKS NNNN: 539.73 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of HAYWARD and DRUMSTICKS NNNN\n",
      "Writing error matrices of HAYWARD and DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "LSTM Archtitecture HAYWARD--> FILLET QQQQ\n",
      "Model Training: HAYWARD--> FILLET QQQQ\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 361ms/step - loss: 0.3731 - val_loss: 0.0578\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3364 - val_loss: 0.0466\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2910 - val_loss: 0.0350\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2266 - val_loss: 0.0244\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1648 - val_loss: 0.0192\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0889 - val_loss: 0.0313\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0397 - val_loss: 0.0807\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0602 - val_loss: 0.1051\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0449 - val_loss: 0.0715\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0286 - val_loss: 0.0477\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0327 - val_loss: 0.0401\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0367 - val_loss: 0.0420\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0368 - val_loss: 0.0505\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0270 - val_loss: 0.0632\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0307 - val_loss: 0.0693\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0376 - val_loss: 0.0622\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0338 - val_loss: 0.0543\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0370 - val_loss: 0.0511\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0312 - val_loss: 0.0492\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0275 - val_loss: 0.0492\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0285 - val_loss: 0.0553\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0241 - val_loss: 0.0596\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0294 - val_loss: 0.0572\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0268 - val_loss: 0.0472\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0310 - val_loss: 0.0402\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0335 - val_loss: 0.0429\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0303 - val_loss: 0.0465\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0328 - val_loss: 0.0519\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0292 - val_loss: 0.0489\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0311 - val_loss: 0.0398\n",
      "\n",
      "\n",
      "Plot for: HAYWARD--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Model Forecasting initated: HAYWARD--> FILLET QQQQ\n",
      "Model prediction initiated : HAYWARD--> FILLET QQQQ\n",
      "2/2 [==============================] - 1s 7ms/step\n",
      "Model prediction completed : HAYWARD--> FILLET QQQQ\n",
      "Storing prediction into DataFrame : HAYWARD--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Plotting prediction with original data : HAYWARD--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : HAYWARD--> FILLET QQQQ\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "Train Score HAYWARD-FILLET QQQQ: 3986.90 MSE\n",
      "Train Score HAYWARD-FILLET QQQQ: 63.14 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of HAYWARD and FILLET QQQQ\n",
      "Writing error matrices of HAYWARD and FILLET QQQQ\n",
      "\n",
      "\n",
      "LSTM Archtitecture LAKEWOOD--> CHICKEN XXXXX - O\n",
      "Model Training: LAKEWOOD--> CHICKEN XXXXX - O\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 380ms/step - loss: 0.1443 - val_loss: 0.0552\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1293 - val_loss: 0.0451\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1143 - val_loss: 0.0341\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0958 - val_loss: 0.0230\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0762 - val_loss: 0.0137\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0595 - val_loss: 0.0117\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0481 - val_loss: 0.0229\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0608 - val_loss: 0.0334\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0476 - val_loss: 0.0244\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0501 - val_loss: 0.0173\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0458 - val_loss: 0.0146\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0452 - val_loss: 0.0145\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0458 - val_loss: 0.0155\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0466 - val_loss: 0.0182\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0487 - val_loss: 0.0173\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0451 - val_loss: 0.0159\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0466 - val_loss: 0.0163\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0503 - val_loss: 0.0145\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0475 - val_loss: 0.0164\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0438 - val_loss: 0.0169\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0519 - val_loss: 0.0179\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0517 - val_loss: 0.0147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0455 - val_loss: 0.0133\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0459 - val_loss: 0.0140\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0471 - val_loss: 0.0129\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0531 - val_loss: 0.0136\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0437 - val_loss: 0.0160\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0413 - val_loss: 0.0183\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0447 - val_loss: 0.0155\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0444 - val_loss: 0.0151\n",
      "\n",
      "\n",
      "Plot for: LAKEWOOD--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Model Forecasting initated: LAKEWOOD--> CHICKEN XXXXX - O\n",
      "Model prediction initiated : LAKEWOOD--> CHICKEN XXXXX - O\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "Model prediction completed : LAKEWOOD--> CHICKEN XXXXX - O\n",
      "Storing prediction into DataFrame : LAKEWOOD--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Plotting prediction with original data : LAKEWOOD--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : LAKEWOOD--> CHICKEN XXXXX - O\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Train Score LAKEWOOD-CHICKEN XXXXX - O: 2250.89 MSE\n",
      "Train Score LAKEWOOD-CHICKEN XXXXX - O: 47.44 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of LAKEWOOD and CHICKEN XXXXX - O\n",
      "Writing error matrices of LAKEWOOD and CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "LSTM Archtitecture LAKEWOOD--> DRUMSTICKS NNNN\n",
      "Model Training: LAKEWOOD--> DRUMSTICKS NNNN\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 361ms/step - loss: 0.1697 - val_loss: 0.1545\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1553 - val_loss: 0.1388\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1389 - val_loss: 0.1205\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1188 - val_loss: 0.0986\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0937 - val_loss: 0.0735\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0706 - val_loss: 0.0473\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0454 - val_loss: 0.0265\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0431 - val_loss: 0.0227\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0496 - val_loss: 0.0232\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0475 - val_loss: 0.0229\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0468 - val_loss: 0.0270\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0372 - val_loss: 0.0298\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0475 - val_loss: 0.0296\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0408 - val_loss: 0.0279\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0436 - val_loss: 0.0252\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0360 - val_loss: 0.0236\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0430 - val_loss: 0.0231\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0396 - val_loss: 0.0235\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0451 - val_loss: 0.0243\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0386 - val_loss: 0.0248\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0348 - val_loss: 0.0249\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0425 - val_loss: 0.0246\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0429 - val_loss: 0.0240\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0365 - val_loss: 0.0235\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0376 - val_loss: 0.0239\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0402 - val_loss: 0.0242\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0420 - val_loss: 0.0249\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0370 - val_loss: 0.0240\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0379 - val_loss: 0.0233\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0423 - val_loss: 0.0246\n",
      "\n",
      "\n",
      "Plot for: LAKEWOOD--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Model Forecasting initated: LAKEWOOD--> DRUMSTICKS NNNN\n",
      "Model prediction initiated : LAKEWOOD--> DRUMSTICKS NNNN\n",
      "2/2 [==============================] - 1s 7ms/step\n",
      "Model prediction completed : LAKEWOOD--> DRUMSTICKS NNNN\n",
      "Storing prediction into DataFrame : LAKEWOOD--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Plotting prediction with original data : LAKEWOOD--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : LAKEWOOD--> DRUMSTICKS NNNN\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Train Score LAKEWOOD-DRUMSTICKS NNNN: 78167.05 MSE\n",
      "Train Score LAKEWOOD-DRUMSTICKS NNNN: 279.58 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of LAKEWOOD and DRUMSTICKS NNNN\n",
      "Writing error matrices of LAKEWOOD and DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "LSTM Archtitecture LAKEWOOD--> FILLET QQQQ\n",
      "Model Training: LAKEWOOD--> FILLET QQQQ\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 7s 360ms/step - loss: 0.5320 - val_loss: 0.0705\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4998 - val_loss: 0.0608\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4588 - val_loss: 0.0500\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4058 - val_loss: 0.0381\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3365 - val_loss: 0.0268\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2478 - val_loss: 0.0213\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1540 - val_loss: 0.0386\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0542 - val_loss: 0.1143\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0879 - val_loss: 0.1344\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0616 - val_loss: 0.0850\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0491 - val_loss: 0.0611\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0510 - val_loss: 0.0576\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0567 - val_loss: 0.0660\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0477 - val_loss: 0.0850\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0404 - val_loss: 0.1075\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0470 - val_loss: 0.1089\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0433 - val_loss: 0.0955\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0458 - val_loss: 0.0839\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0371 - val_loss: 0.0816\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0430 - val_loss: 0.0843\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0397 - val_loss: 0.0947\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0364 - val_loss: 0.1048\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0430 - val_loss: 0.1022\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0376 - val_loss: 0.0915\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0480 - val_loss: 0.0816\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0476 - val_loss: 0.0811\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0468 - val_loss: 0.0910\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0567 - val_loss: 0.0948\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0520 - val_loss: 0.0902\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0525 - val_loss: 0.0877\n",
      "\n",
      "\n",
      "Plot for: LAKEWOOD--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Model Forecasting initated: LAKEWOOD--> FILLET QQQQ\n",
      "Model prediction initiated : LAKEWOOD--> FILLET QQQQ\n",
      "2/2 [==============================] - 2s 7ms/step\n",
      "Model prediction completed : LAKEWOOD--> FILLET QQQQ\n",
      "Storing prediction into DataFrame : LAKEWOOD--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Plotting prediction with original data : LAKEWOOD--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : LAKEWOOD--> FILLET QQQQ\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Train Score LAKEWOOD-FILLET QQQQ: 1712.44 MSE\n",
      "Train Score LAKEWOOD-FILLET QQQQ: 41.38 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of LAKEWOOD and FILLET QQQQ\n",
      "Writing error matrices of LAKEWOOD and FILLET QQQQ\n",
      "\n",
      "\n",
      "LSTM Archtitecture RICHMOND CA--> CHICKEN XXXXX - O\n",
      "Model Training: RICHMOND CA--> CHICKEN XXXXX - O\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 366ms/step - loss: 0.3220 - val_loss: 0.2130\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2981 - val_loss: 0.1925\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2683 - val_loss: 0.1680\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2344 - val_loss: 0.1379\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1899 - val_loss: 0.1009\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1486 - val_loss: 0.0598\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0831 - val_loss: 0.0289\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0527 - val_loss: 0.0506\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0737 - val_loss: 0.0473\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0564 - val_loss: 0.0277\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0474 - val_loss: 0.0266\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0470 - val_loss: 0.0263\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0493 - val_loss: 0.0255\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0469 - val_loss: 0.0267\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0396 - val_loss: 0.0302\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0429 - val_loss: 0.0338\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0452 - val_loss: 0.0328\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0453 - val_loss: 0.0275\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0361 - val_loss: 0.0250\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0419 - val_loss: 0.0249\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0430 - val_loss: 0.0255\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0405 - val_loss: 0.0266\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0402 - val_loss: 0.0278\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0390 - val_loss: 0.0277\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0346 - val_loss: 0.0283\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0456 - val_loss: 0.0280\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0359 - val_loss: 0.0265\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0439 - val_loss: 0.0261\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0371 - val_loss: 0.0266\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0418 - val_loss: 0.0271\n",
      "\n",
      "\n",
      "Plot for: RICHMOND CA--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Model Forecasting initated: RICHMOND CA--> CHICKEN XXXXX - O\n",
      "Model prediction initiated : RICHMOND CA--> CHICKEN XXXXX - O\n",
      "2/2 [==============================] - 1s 6ms/step\n",
      "Model prediction completed : RICHMOND CA--> CHICKEN XXXXX - O\n",
      "Storing prediction into DataFrame : RICHMOND CA--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Plotting prediction with original data : RICHMOND CA--> CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : RICHMOND CA--> CHICKEN XXXXX - O\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "Train Score RICHMOND CA-CHICKEN XXXXX - O: 7595.99 MSE\n",
      "Train Score RICHMOND CA-CHICKEN XXXXX - O: 87.15 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of RICHMOND CA and CHICKEN XXXXX - O\n",
      "Writing error matrices of RICHMOND CA and CHICKEN XXXXX - O\n",
      "\n",
      "\n",
      "LSTM Archtitecture RICHMOND CA--> DRUMSTICKS NNNN\n",
      "Model Training: RICHMOND CA--> DRUMSTICKS NNNN\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 361ms/step - loss: 0.2462 - val_loss: 0.1881\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2317 - val_loss: 0.1730\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2137 - val_loss: 0.1557\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1945 - val_loss: 0.1354\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1737 - val_loss: 0.1109\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1465 - val_loss: 0.0813\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1032 - val_loss: 0.0464\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0656 - val_loss: 0.0132\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0525 - val_loss: 0.0049\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0585 - val_loss: 0.0048\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0491 - val_loss: 0.0054\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0515 - val_loss: 0.0086\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0468 - val_loss: 0.0107\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0486 - val_loss: 0.0090\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0432 - val_loss: 0.0059\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0420 - val_loss: 0.0047\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0511 - val_loss: 0.0046\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0451 - val_loss: 0.0049\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0445 - val_loss: 0.0055\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0382 - val_loss: 0.0058\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0438 - val_loss: 0.0057\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0514 - val_loss: 0.0055\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0507 - val_loss: 0.0059\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0460 - val_loss: 0.0066\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0417 - val_loss: 0.0065\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0380 - val_loss: 0.0053\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0443 - val_loss: 0.0048\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0406 - val_loss: 0.0050\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0416 - val_loss: 0.0062\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0465 - val_loss: 0.0059\n",
      "\n",
      "\n",
      "Plot for: RICHMOND CA--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Model Forecasting initated: RICHMOND CA--> DRUMSTICKS NNNN\n",
      "Model prediction initiated : RICHMOND CA--> DRUMSTICKS NNNN\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "Model prediction completed : RICHMOND CA--> DRUMSTICKS NNNN\n",
      "Storing prediction into DataFrame : RICHMOND CA--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Plotting prediction with original data : RICHMOND CA--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : RICHMOND CA--> DRUMSTICKS NNNN\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Train Score RICHMOND CA-DRUMSTICKS NNNN: 343077.53 MSE\n",
      "Train Score RICHMOND CA-DRUMSTICKS NNNN: 585.73 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of RICHMOND CA and DRUMSTICKS NNNN\n",
      "Writing error matrices of RICHMOND CA and DRUMSTICKS NNNN\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Archtitecture RICHMOND CA--> FILLET QQQQ\n",
      "Model Training: RICHMOND CA--> FILLET QQQQ\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 353ms/step - loss: 0.4616 - val_loss: 0.0529\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4350 - val_loss: 0.0468\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4080 - val_loss: 0.0397\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3769 - val_loss: 0.0320\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3357 - val_loss: 0.0241\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2734 - val_loss: 0.0170\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2053 - val_loss: 0.0137\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1270 - val_loss: 0.0242\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0502 - val_loss: 0.0712\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0650 - val_loss: 0.0938\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0399 - val_loss: 0.0644\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0332 - val_loss: 0.0446\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0493 - val_loss: 0.0419\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0448 - val_loss: 0.0476\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0343 - val_loss: 0.0607\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0280 - val_loss: 0.0720\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0336 - val_loss: 0.0740\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0313 - val_loss: 0.0674\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0376 - val_loss: 0.0606\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0268 - val_loss: 0.0568\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0345 - val_loss: 0.0575\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0263 - val_loss: 0.0585\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0256 - val_loss: 0.0592\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0304 - val_loss: 0.0597\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0264 - val_loss: 0.0611\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0301 - val_loss: 0.0641\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0268 - val_loss: 0.0575\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0372 - val_loss: 0.0529\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0281 - val_loss: 0.0544\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0293 - val_loss: 0.0601\n",
      "\n",
      "\n",
      "Plot for: RICHMOND CA--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Model Forecasting initated: RICHMOND CA--> FILLET QQQQ\n",
      "Model prediction initiated : RICHMOND CA--> FILLET QQQQ\n",
      "2/2 [==============================] - 2s 7ms/step\n",
      "Model prediction completed : RICHMOND CA--> FILLET QQQQ\n",
      "Storing prediction into DataFrame : RICHMOND CA--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Plotting prediction with original data : RICHMOND CA--> FILLET QQQQ\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : RICHMOND CA--> FILLET QQQQ\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "Train Score RICHMOND CA-FILLET QQQQ: 6518.18 MSE\n",
      "Train Score RICHMOND CA-FILLET QQQQ: 80.74 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of RICHMOND CA and FILLET QQQQ\n",
      "Writing error matrices of RICHMOND CA and FILLET QQQQ\n",
      "\n",
      "\n",
      "LSTM Archtitecture S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "Model Training: S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 362ms/step - loss: 0.1654 - val_loss: 0.2391\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1536 - val_loss: 0.2206\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1401 - val_loss: 0.1967\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1217 - val_loss: 0.1658\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1016 - val_loss: 0.1282\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0747 - val_loss: 0.0844\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0528 - val_loss: 0.0411\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0365 - val_loss: 0.0179\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0500 - val_loss: 0.0166\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0368 - val_loss: 0.0228\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0394 - val_loss: 0.0334\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0431 - val_loss: 0.0411\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0371 - val_loss: 0.0405\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0363 - val_loss: 0.0354\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0395 - val_loss: 0.0287\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0367 - val_loss: 0.0259\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0354 - val_loss: 0.0248\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0383 - val_loss: 0.0246\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0383 - val_loss: 0.0267\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0377 - val_loss: 0.0296\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0360 - val_loss: 0.0321\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0391 - val_loss: 0.0298\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0357 - val_loss: 0.0285\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0366 - val_loss: 0.0268\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0323 - val_loss: 0.0241\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0403 - val_loss: 0.0260\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0360 - val_loss: 0.0258\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0352 - val_loss: 0.0244\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0326 - val_loss: 0.0238\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0321 - val_loss: 0.0239\n",
      "\n",
      "\n",
      "Plot for: S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "\n",
      "\n",
      "Model Forecasting initated: S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "Model prediction initiated : S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "2/2 [==============================] - 1s 7ms/step\n",
      "Model prediction completed : S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "Storing prediction into DataFrame : S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "\n",
      "\n",
      "Plotting prediction with original data : S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : S SAN FRANCISCO BUS CTR--> BEEF OOOO - GT\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Train Score S SAN FRANCISCO BUS CTR-BEEF OOOO - GT: 29641.15 MSE\n",
      "Train Score S SAN FRANCISCO BUS CTR-BEEF OOOO - GT: 172.17 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of S SAN FRANCISCO BUS CTR and BEEF OOOO - GT\n",
      "Writing error matrices of S SAN FRANCISCO BUS CTR and BEEF OOOO - GT\n",
      "\n",
      "\n",
      "LSTM Archtitecture S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "Model Training: S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 8s 385ms/step - loss: 0.2913 - val_loss: 0.2597\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2634 - val_loss: 0.2317\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2340 - val_loss: 0.1993\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2019 - val_loss: 0.1603\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1637 - val_loss: 0.1140\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1114 - val_loss: 0.0631\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0732 - val_loss: 0.0258\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0622 - val_loss: 0.0303\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0515 - val_loss: 0.0290\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0543 - val_loss: 0.0233\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0537 - val_loss: 0.0250\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0537 - val_loss: 0.0276\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0554 - val_loss: 0.0270\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0653 - val_loss: 0.0244\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0528 - val_loss: 0.0229\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0487 - val_loss: 0.0224\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0523 - val_loss: 0.0226\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0514 - val_loss: 0.0227\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0524 - val_loss: 0.0227\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0479 - val_loss: 0.0226\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0511 - val_loss: 0.0226\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0460 - val_loss: 0.0226\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0436 - val_loss: 0.0227\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0586 - val_loss: 0.0228\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0495 - val_loss: 0.0225\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0527 - val_loss: 0.0225\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0506 - val_loss: 0.0220\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0496 - val_loss: 0.0219\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0451 - val_loss: 0.0219\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0509 - val_loss: 0.0219\n",
      "\n",
      "\n",
      "Plot for: S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Model Forecasting initated: S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "Model prediction initiated : S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "Model prediction completed : S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "Storing prediction into DataFrame : S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Plotting prediction with original data : S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "\n",
      "\n",
      "Calculating MSE and RMSE : S SAN FRANCISCO BUS CTR--> DRUMSTICKS NNNN\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Train Score S SAN FRANCISCO BUS CTR-DRUMSTICKS NNNN: 27307.46 MSE\n",
      "Train Score S SAN FRANCISCO BUS CTR-DRUMSTICKS NNNN: 165.25 RMSE\n",
      "\n",
      "\n",
      "Writing predicted results of S SAN FRANCISCO BUS CTR and DRUMSTICKS NNNN\n",
      "Writing error matrices of S SAN FRANCISCO BUS CTR and DRUMSTICKS NNNN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in df_new['Location'].unique():\n",
    "    df= df_new[df_new['Location']==i]\n",
    "    for j in df['Item'].unique():\n",
    "        item_data= df[df[\"Item\"]==j]\n",
    "\n",
    "        item_data= item_data.drop(['Location', 'Item', 'Amount', 'Quantity', 'Mv_Amt'], axis=1)\n",
    "        train_dates = pd.to_datetime(item_data['Date'])  #collecting date \n",
    "        item_data = item_data.set_index('Date')\n",
    "#         print(item_data)\n",
    "        \n",
    "        #Modelling \n",
    "        \n",
    "        #Splitting \n",
    "        a= int(len(item_data)*0.75)\n",
    "        train,test = item_data[:a], item_data[a:]\n",
    "        \n",
    "        #COnverting into same scale \n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(train) \n",
    "        \n",
    "        #Transforming train and test \n",
    "        train_scaled = scaler.transform(train)\n",
    "        test_scaled = scaler.transform(test)\n",
    "        \n",
    "        #Empty lists to be populated using formatted training data\n",
    "        trainX = []\n",
    "        trainY = []\n",
    "\n",
    "        n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "        n_past=seq_size = 5  # Number of past days we want to use to predict the future.\n",
    "        n_features = 1 ## number of features. This dataset is univariate so it is 1\n",
    "\n",
    "        #Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "\n",
    "        for num in range(n_past, len(train_scaled) - n_future +1):\n",
    "            trainX.append(train_scaled[num - n_past:num, 0:train.shape[1]])\n",
    "            trainY.append(train_scaled[num + n_future - 1:num + n_future, 0])\n",
    "        \n",
    "        #Converting to Numpy format\n",
    "        trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "        \n",
    "#         print(f'Location: {i} and  Item: {j}')\n",
    "        \n",
    "#         print('trainX shape == {}.'.format(trainX.shape))\n",
    "#         print('trainY shape == {}.'.format(trainY.shape))\n",
    "        \n",
    "#         print(\"\\n\")\n",
    "        print(f\"LSTM Archtitecture {i}--> {j}\")\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "        model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "        model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "#         model.summary()\n",
    "#         print(\"\\n\")\n",
    "        print(f\"Model Training: {i}--> {j}\")\n",
    "        history = model.fit(trainX, trainY, epochs=30, batch_size=16, validation_split=0.2, verbose=1)\n",
    "        \n",
    "        #Plotting traning and validation curve \n",
    "        print(\"\\n\")\n",
    "        print(f\"Plot for: {i}--> {j}\")\n",
    "        title = i+\"-->\"+j\n",
    "        \n",
    "#         ax.set_title(title)\n",
    "#         plt.plot(history.history['loss'], label='Training loss')\n",
    "#         plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "#         ax.set_ylabel('Quantity')\n",
    "#         ax.set_xlabel('Date')\n",
    "#         plt.legend()\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print(f\"Model Forecasting initated: {i}--> {j}\")\n",
    "\n",
    "        n_past= seq_size= 1        #Number of past days we want to use to predict the future.\n",
    "        n_days_for_prediction = 36     #let us predict past 12 days\n",
    "        \n",
    "        time_series = test.index  #Get dates for test data\n",
    "        \n",
    "        #Creating date time periods for next 90 days \n",
    "        predict_period_dates = pd.date_range(list(time_series)[-n_past], periods=n_days_for_prediction, freq='W').tolist()\n",
    "        \n",
    "        print(f\"Model prediction initiated : {i}--> {j}\")\n",
    "        #Make prediction\n",
    "        prediction = model.predict(trainX[-n_days_for_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
    "        \n",
    "        ### Inverse transform to before scaling so we get actual numbers\n",
    "        rescaled_prediction = scaler.inverse_transform(prediction)[:,0]\n",
    "        \n",
    "        print(f\"Model prediction completed : {i}--> {j}\")\n",
    "        # Convert timestamp to date\n",
    "        forecast_dates = []\n",
    "        for time_i in predict_period_dates:\n",
    "            forecast_dates.append(time_i.date())\n",
    "        \n",
    "        print(f\"Storing prediction into DataFrame : {i}--> {j}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        #Creating/saving prediction into dataframe \n",
    "        df_forecast= pd.DataFrame({'Date':np.array(forecast_dates), 'Pred_Quantity':rescaled_prediction})\n",
    "        df_forecast['Date']=pd.to_datetime(df_forecast['Date'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #reset index\n",
    "#         data_df2= item_data.reset_index()\n",
    "        \n",
    "#         original = data_df2[['Date', 'Quantity']]\n",
    "#         original['Date']=pd.to_datetime(original['Date'])\n",
    "#         original = original.loc[original['Date'] >= '2020-01-02']\n",
    "        \n",
    "#         original= original.tail(90)\n",
    "        \n",
    "#         print(\"\\n\")\n",
    "        print(f\"Plotting prediction with original data : {i}--> {j}\")\n",
    "        \n",
    "#         plt.figure(figsize=(10,10)) \n",
    "#         sns.lineplot(original['Date'], original['Quantity'])\n",
    "#         sns.lineplot(df_forecast['Date'], df_forecast['Quantity'])\n",
    "#         print(f\"Model Forecasting complted  : {i}--> {j}\")\n",
    "   \n",
    "        print(\"\\n\")\n",
    "        print(f\"Calculating MSE and RMSE : {i}--> {j}\")\n",
    "        #Prediction testing\n",
    "        trainPredict = model.predict(trainX)\n",
    "        train_inverse = scaler.inverse_transform(train_scaled)\n",
    "        \n",
    "        import math\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        n_past1=5\n",
    "\n",
    "        MSE_Score = mean_squared_error(train_inverse[n_past1:], trainPredict[:,0])\n",
    "        print(f'Train Score {i}-{j}: %.2f MSE' % (MSE_Score))\n",
    "\n",
    "        RMSE_Score = math.sqrt(mean_squared_error(train_inverse[n_past1:], trainPredict[:,0]))\n",
    "        print(f'Train Score {i}-{j}: %.2f RMSE' % (RMSE_Score))\n",
    "        \n",
    "        #Saving Results \n",
    "        df_forecast['Location']= i\n",
    "        df_forecast['Item']=j\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(f'Writing predicted results of {i} and {j}')\n",
    "        predction_output = \"ModelOut\\All_out\\moving_avg\\Output\\Output -\" +i+\"-\"+j+\".xlsx\"\n",
    "        df_forecast.to_excel(predction_output, index= False)\n",
    "        \n",
    "        col_names =  ['MSE_Score', 'RMSE_Score']\n",
    "        Error_matric= pd.DataFrame(columns = col_names)\n",
    "        \n",
    "        my_out = {'MSE_Score': MSE_Score, 'RMSE_Score': RMSE_Score}\n",
    "        Error_matric.loc[len(Error_matric)] = my_out \n",
    "        \n",
    "        Error_matric['Location']=i\n",
    "        Error_matric['Item']=j\n",
    "        \n",
    "        print(f'Writing error matrices of {i} and {j}')\n",
    "        print(\"\\n\")\n",
    "        Error_output = \"ModelOut\\All_out\\moving_avg\\Error\\Output_Error -\" +i+\"-\"+j+\".xlsx\"\n",
    "        Error_matric.to_excel(Error_output, index= False)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b15a0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72f07c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use glob to get all the csv files\n",
    "# in the folder\n",
    "path = 'C:\\\\Users\\\\Ramshankar\\\\OneDrive - iLink Systems Inc\\\\Documents\\\\Costco\\\\Code\\\\ModelOut\\\\All_out\\\\moving_avg\\\\Output\\\\'\n",
    "out_files = glob.glob(os.path.join(path, \"*.xlsx\"))\n",
    "\n",
    "dfs= []\n",
    "\n",
    "\n",
    "for f in out_files:\n",
    "    dfs.append(pd.read_excel(f))\n",
    "df_out=pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "326ccf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pred_Quantity</th>\n",
       "      <th>Location</th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>91.620087</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>91.028236</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>91.978828</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>96.864319</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-24</td>\n",
       "      <td>101.792259</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Pred_Quantity Location               Item\n",
       "0 2022-03-27      91.620087  FREMONT  CHICKEN XXXXX - O\n",
       "1 2022-04-03      91.028236  FREMONT  CHICKEN XXXXX - O\n",
       "2 2022-04-10      91.978828  FREMONT  CHICKEN XXXXX - O\n",
       "3 2022-04-17      96.864319  FREMONT  CHICKEN XXXXX - O\n",
       "4 2022-04-24     101.792259  FREMONT  CHICKEN XXXXX - O"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e5c95",
   "metadata": {},
   "source": [
    "### Merging Weekly MV and forecasted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "348832ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2099, 7)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62565a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Mv_Qty</th>\n",
       "      <th>Mv_Amt</th>\n",
       "      <th>Location</th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>86.101210</td>\n",
       "      <td>429.645000</td>\n",
       "      <td>55.004790</td>\n",
       "      <td>274.473889</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>63.834068</td>\n",
       "      <td>318.532000</td>\n",
       "      <td>63.941686</td>\n",
       "      <td>319.069000</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>45.320977</td>\n",
       "      <td>226.151667</td>\n",
       "      <td>65.085418</td>\n",
       "      <td>324.776222</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>44.333068</td>\n",
       "      <td>221.222000</td>\n",
       "      <td>51.162704</td>\n",
       "      <td>255.301889</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>48.167670</td>\n",
       "      <td>240.356667</td>\n",
       "      <td>45.940572</td>\n",
       "      <td>229.243444</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>CHICKEN XXXXX - O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>113.512925</td>\n",
       "      <td>146.431667</td>\n",
       "      <td>113.895782</td>\n",
       "      <td>146.925556</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>97.404393</td>\n",
       "      <td>125.651667</td>\n",
       "      <td>107.079245</td>\n",
       "      <td>138.132222</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>93.240305</td>\n",
       "      <td>120.280000</td>\n",
       "      <td>101.385874</td>\n",
       "      <td>130.787778</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>94.381132</td>\n",
       "      <td>121.751667</td>\n",
       "      <td>95.008610</td>\n",
       "      <td>122.561111</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>88.660853</td>\n",
       "      <td>114.372500</td>\n",
       "      <td>92.094096</td>\n",
       "      <td>118.801389</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2099 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Quantity      Amount      Mv_Qty      Mv_Amt  \\\n",
       "0    2020-01-19   86.101210  429.645000   55.004790  274.473889   \n",
       "1    2020-01-26   63.834068  318.532000   63.941686  319.069000   \n",
       "2    2020-02-02   45.320977  226.151667   65.085418  324.776222   \n",
       "3    2020-02-09   44.333068  221.222000   51.162704  255.301889   \n",
       "4    2020-02-16   48.167670  240.356667   45.940572  229.243444   \n",
       "...         ...         ...         ...         ...         ...   \n",
       "2094 2022-10-30  113.512925  146.431667  113.895782  146.925556   \n",
       "2095 2022-11-06   97.404393  125.651667  107.079245  138.132222   \n",
       "2096 2022-11-13   93.240305  120.280000  101.385874  130.787778   \n",
       "2097 2022-11-20   94.381132  121.751667   95.008610  122.561111   \n",
       "2098 2022-11-27   88.660853  114.372500   92.094096  118.801389   \n",
       "\n",
       "                     Location               Item  \n",
       "0                     FREMONT  CHICKEN XXXXX - O  \n",
       "1                     FREMONT  CHICKEN XXXXX - O  \n",
       "2                     FREMONT  CHICKEN XXXXX - O  \n",
       "3                     FREMONT  CHICKEN XXXXX - O  \n",
       "4                     FREMONT  CHICKEN XXXXX - O  \n",
       "...                       ...                ...  \n",
       "2094  S SAN FRANCISCO BUS CTR    DRUMSTICKS NNNN  \n",
       "2095  S SAN FRANCISCO BUS CTR    DRUMSTICKS NNNN  \n",
       "2096  S SAN FRANCISCO BUS CTR    DRUMSTICKS NNNN  \n",
       "2097  S SAN FRANCISCO BUS CTR    DRUMSTICKS NNNN  \n",
       "2098  S SAN FRANCISCO BUS CTR    DRUMSTICKS NNNN  \n",
       "\n",
       "[2099 rows x 7 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "584e235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge= pd.merge(data, df_out, on= ['Date', 'Item', 'Location'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94d25d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Mv_Qty</th>\n",
       "      <th>Mv_Amt</th>\n",
       "      <th>Location</th>\n",
       "      <th>Item</th>\n",
       "      <th>Pred_Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>113.512925</td>\n",
       "      <td>146.431667</td>\n",
       "      <td>113.895782</td>\n",
       "      <td>146.925556</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "      <td>171.714386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>97.404393</td>\n",
       "      <td>125.651667</td>\n",
       "      <td>107.079245</td>\n",
       "      <td>138.132222</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "      <td>168.054871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>93.240305</td>\n",
       "      <td>120.280000</td>\n",
       "      <td>101.385874</td>\n",
       "      <td>130.787778</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "      <td>164.886780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>94.381132</td>\n",
       "      <td>121.751667</td>\n",
       "      <td>95.008610</td>\n",
       "      <td>122.561111</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "      <td>160.854660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>88.660853</td>\n",
       "      <td>114.372500</td>\n",
       "      <td>92.094096</td>\n",
       "      <td>118.801389</td>\n",
       "      <td>S SAN FRANCISCO BUS CTR</td>\n",
       "      <td>DRUMSTICKS NNNN</td>\n",
       "      <td>158.627563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Quantity      Amount      Mv_Qty      Mv_Amt  \\\n",
       "2094 2022-10-30  113.512925  146.431667  113.895782  146.925556   \n",
       "2095 2022-11-06   97.404393  125.651667  107.079245  138.132222   \n",
       "2096 2022-11-13   93.240305  120.280000  101.385874  130.787778   \n",
       "2097 2022-11-20   94.381132  121.751667   95.008610  122.561111   \n",
       "2098 2022-11-27   88.660853  114.372500   92.094096  118.801389   \n",
       "\n",
       "                     Location             Item  Pred_Quantity  \n",
       "2094  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN     171.714386  \n",
       "2095  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN     168.054871  \n",
       "2096  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN     164.886780  \n",
       "2097  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN     160.854660  \n",
       "2098  S SAN FRANCISCO BUS CTR  DRUMSTICKS NNNN     158.627563  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4cbf50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = data_merge.rename(columns= {'Pred_Quantity': 'Forecasted_Quantity'})\n",
    "data_merge['Forecasted_Quantity']= data_merge['Forecasted_Quantity'].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e8b82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge.to_excel(loc + 'Data_MV_Forecast_Weekly.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6a467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
